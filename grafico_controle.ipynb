{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKESBNBgKnLaeO6btsMdN3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "Dl2RQnCjMUoI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Leitura dos dataframes de base e target.\n",
        "Define as métricas que devem ser analisadas.\n",
        "\"\"\"\n",
        "\n",
        "df_base = pd.read_csv('/content/data_base.csv')\n",
        "df_target = pd.read_csv('/content/data_target.csv')\n",
        "\n",
        "possible_metrics = ['cpu_app', 'memory_app', 'cpu_db', 'memory_db', 'rows_fetched', 'rows_returned', 'db_commits', 'response_time']"
      ],
      "metadata": {
        "id": "l_EsQ1SWMUlF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Remove colunas não utilizadas não utilizadas do csv.\n",
        "\"\"\"\n",
        "removable_columns = ['timestamp_begin', 'timestamp_end', 'total_calls']\n",
        "df_base.drop(removable_columns, axis=1, inplace=True)\n",
        "df_target.drop(removable_columns, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "oq2C00J8i7Eh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A função para recuperar os outliers está utilizando a regra iqr (inter quartil)\n",
        "No nosso caso, encontramos que a remoção dos outliers abaixo do minimo definido\n",
        "referentes as chamadas totais faz mais sentido, justamente por remover os pontos\n",
        "de dados da amostragem que não nos interessa, que seria o ínicio e fim do teste,\n",
        "onde nem os caches, nem os buffers foram definidos ainda. Além disso, os dados acima\n",
        "do máximo definido pode representar sobrecarga no teste, gerando um estresse, que pode\n",
        "impactar negativamente nas amostras coletadas.\n",
        "\"\"\"\n",
        "def recupera_outliers(df, target):\n",
        "  outliers_indexes = []\n",
        "\n",
        "  q1 = df[target].quantile(0.25)\n",
        "  q3 = df[target].quantile(0.75)\n",
        "  iqr = q3-q1\n",
        "  maximum = q3 + (1.5 * iqr)\n",
        "  minimum = q1 - (1.5 * iqr)\n",
        "  outlier_samples = df[(df[target] < minimum) | (df[target] > maximum)]\n",
        "  outliers_indexes.extend(outlier_samples.index.tolist())\n",
        "\n",
        "  outliers_indexes = list(set(outliers_indexes))\n",
        "  return outliers_indexes"
      ],
      "metadata": {
        "id": "w34QA4YMR_LP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Recupera regressão linear utilizando OLS para exibir valores do R².\n",
        "\"\"\"\n",
        "\n",
        "def recupera_regressao_linear(df, target='cpu'):\n",
        "  x = sm.add_constant(df.drop(possible_metrics, axis=1))\n",
        "\n",
        "  results = sm.OLS(df[target], x).fit()\n",
        "\n",
        "  return results.summary()"
      ],
      "metadata": {
        "id": "lZEDNHjVMUX_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Recupera o R² ajustado para a regressão linear do conjunto de dados olhando\n",
        "para as possíveis métricas. Apenas no conjunto base que é o responsável pela escala\n",
        "Seleciona métricas que possuem R² ajustado maior ou igual a 0.67.\n",
        "\"\"\"\n",
        "analyzable_metrics = []\n",
        "for metric in possible_metrics:\n",
        "  adjustedR2 = recupera_regressao_linear(df_base, metric).tables[0].data[1][3].strip()\n",
        "  print(\"Métrica: \", metric)\n",
        "  print(\"R² Ajustado: \", adjustedR2)\n",
        "  if float(adjustedR2) >= 0.67:\n",
        "    analyzable_metrics.append(metric)\n",
        "\n",
        "print('\\nMétricas passíveis de análise:')\n",
        "print(analyzable_metrics)"
      ],
      "metadata": {
        "id": "2YfL-CtjyOUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Faz o plot do gráfico de comparação entre dois conjuntos de dados,\n",
        "olhando o parâmetro de métrica enviado.\n",
        "\"\"\"\n",
        "\n",
        "# Plote do gráfico de acordo com a métrica selecionada\n",
        "\n",
        "def plot_grafico(df_base, df_target, metric):\n",
        "  plt.plot(df_base[metric], 'b-', label='Base')\n",
        "  plt.plot(df_target[metric], 'r--', label='Target')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.xlabel('Período de tempo (minuto)', fontsize = 14)\n",
        "  plt.ylabel(f'{metric}', fontsize = 14)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eVYpqBd2ckGZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Recupera os coeficientes das variáveis independentes (chamadas aos endpoints) e\n",
        "dependente (valor da métrica) utilizando uma regressão linear múltipla com o\n",
        "algoritmo de OLS (Ordinary Least Squares) [https://en.wikipedia.org/wiki/Ordinary_least_squares]\n",
        "Obtivemos melhores resultados a partir da utilização desse algoritmo em comparação com o\n",
        "sklearn LinearRegressionModel.\n",
        "\"\"\"\n",
        "\n",
        "def recupera_coeficientes(df, target):\n",
        "  x = sm.add_constant(df.drop(possible_metrics, axis=1))\n",
        "\n",
        "  results = sm.OLS(df[target], x).fit()\n",
        "\n",
        "  # Coef da variável dependente\n",
        "  intercept = float(results.summary().tables[1].data[1][1].strip())\n",
        "\n",
        "  coef_independente = []\n",
        "  for i in range(23):\n",
        "    coef_independente.append(float(results.summary().tables[1].data[i+2][1].strip()))\n",
        "\n",
        "  return intercept, coef_independente"
      ],
      "metadata": {
        "id": "5hAPkL6ErPev"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Recupera a soma dos coeficientes para ser utilizado na equação que aplica a escala\n",
        "dos dados a partir da relação entre impacto da carga nos valores das métricas.\n",
        "\"\"\"\n",
        "\n",
        "def recupera_soma_coeficientes(df, intercept, coef_independente, index_line):\n",
        "\n",
        "  return sum([value*df.iloc[index_line][index] for index, value in enumerate(coef_independente)])+intercept"
      ],
      "metadata": {
        "id": "50BvrAo2tEnS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Traz para escala do base todas as métricas de desempenho do conjunto de dados target dos testes.\n",
        "Sobreescreve os valores das métricas em um novo dataframe de dados que estão em escala.\n",
        "\"\"\"\n",
        "\n",
        "df_target_scaled = df_target.copy()\n",
        "\n",
        "for metric in analyzable_metrics:\n",
        "  intercept_base, coef_independente_base = recupera_coeficientes(df_base, metric)\n",
        "\n",
        "  for index, Mb in enumerate(df_base[metric]):\n",
        "    df_target_scaled[metric][index] = (\n",
        "      Mb * (\n",
        "        recupera_soma_coeficientes(df_target, intercept_base, coef_independente_base, index)/recupera_soma_coeficientes(df_base, intercept_base, coef_independente_base, index)\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "id": "jwNYOwPar8FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base.name = 'Teste base'\n",
        "df_target.name = 'Teste alvo'\n",
        "df_target_scaled.name = 'Teste base normalizado'"
      ],
      "metadata": {
        "id": "1JrXIU-4DfaG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grafico(df_base, df_target, metric, ax):\n",
        "  ax.plot(df_base[metric], 'b-', label=df_base.name)\n",
        "  ax.plot(df_target[metric], 'r--', label=df_target.name)\n",
        "  ax.legend(loc='lower right')\n",
        "  ax.set_xlabel('Período de tempo (minuto)', fontsize = 14)\n",
        "  ax.set_ylabel(f'{metric}', fontsize = 14)"
      ],
      "metadata": {
        "id": "m9cQLf8S6YQb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Realiza a impressão dos gráficos de comparação entre as métricas em escala e normais.\n",
        "\"\"\"\n",
        "fig, ax = plt.subplots(len(analyzable_metrics), 3, figsize=(25,25))\n",
        "for index, metric in enumerate(analyzable_metrics):\n",
        "  plot_grafico(df_base, df_target, metric, ax[index, 0])\n",
        "  plot_grafico(df_base, df_target_scaled, metric, ax[index, 1])\n",
        "  plot_grafico(df_target_scaled, df_target, metric, ax[index, 2])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FbMNpaFyorZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Remove os outliers de ambos conjuntos de dados (base e target) para cada métrica individualmente.\n",
        "Para manter o tamanho da amostra, são removidos os índices de outliers tanto encontrados na\n",
        "amostra do teste base, quanto target. O corte IQR feito garante um conjunto de dados mais\n",
        "normal do que o original, satisfazendo o pressuposto do gráfico de controle de normalidade\n",
        "nos outputs.\n",
        "\"\"\"\n",
        "dfs_target_scaled = {}\n",
        "dfs_target = {}\n",
        "for metric in analyzable_metrics:\n",
        "  dfs_target[metric] = df_target.copy()\n",
        "  dfs_target_scaled[metric] = df_target_scaled.copy()\n",
        "  outliers_indexes = list(set([*recupera_outliers(dfs_target[metric], metric), *recupera_outliers(dfs_target_scaled[metric], metric)]))\n",
        "  dfs_target[metric].drop(outliers_indexes, inplace=True)\n",
        "  dfs_target[metric].reset_index(drop=True, inplace=True)\n",
        "\n",
        "  dfs_target_scaled[metric].drop(outliers_indexes, inplace=True)\n",
        "  dfs_target_scaled[metric].reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "jhmWdqx0sN-3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Faz o plote dos gráficos de controle cuja distribuição base e alvo estão normais.\n",
        "Verificação é feita usando o teste de Shapiro-Wilk. Limites inferiores e superiores\n",
        "definidos a partir dos percentis 5 e 95 do conjunto de dados base.\n",
        "\"\"\"\n",
        "LSC = {} # Limite superior de controle\n",
        "LIC = {} # Limite inferior de controle\n",
        "\n",
        "for metric in analyzable_metrics:\n",
        "  # Verifica normalidade a partir do shapiro (Se pvalue < 0.05, conjunto de dados não normal)\n",
        "  _, pvalue_base = stats.shapiro(dfs_target[metric][metric])\n",
        "  _, pvalue_target_scaled = stats.shapiro(dfs_target_scaled[metric][metric])\n",
        "  if pvalue_base < 0.05 or pvalue_target_scaled < 0.05:\n",
        "    continue\n",
        "\n",
        "  df_base_statistic = dfs_target_scaled[metric].describe(percentiles=[.05, .95])\n",
        "\n",
        "  # Plot do gráfico de controle\n",
        "  fig, ax = plt.subplots(figsize = (10, 6))\n",
        "\n",
        "  # Criação do eixo principal\n",
        "  ax.plot(dfs_target[metric][metric], linestyle='-', marker='o', color='blue', label='Alvo')\n",
        "\n",
        "  # Criação do limite superior\n",
        "  LSC[metric] = df_base_statistic[metric]['95%']\n",
        "  ax.axhline(LSC[metric], color='red')\n",
        "\n",
        "  # Criação do limite inferior\n",
        "  LIC[metric] = df_base_statistic[metric]['5%']\n",
        "  ax.axhline(LIC[metric], color='red')\n",
        "\n",
        "  # Criação da linha de média\n",
        "  ax.axhline(df_base_statistic[metric]['mean'], color='green')\n",
        "\n",
        "  # Título do gráfico\n",
        "  ax.set_title(f'Gráfico de controle ({metric})')\n",
        "\n",
        "  # Nomeação dos eixos\n",
        "  ax.set(xlabel='Período de tempo (minuto)', ylabel=metric)\n",
        "\n",
        "  # Nomeação lateral do gráfico a partir do limite do eixo x\n",
        "  left, right = ax.get_xlim()\n",
        "  ax.text(right + 0.3, LSC[metric], \"LSC = \" + str(\"{:.2f}\".format(LSC[metric])), color='red')\n",
        "  ax.text(right + 0.3, df_base_statistic[metric]['mean'], r'$\\bar{x}$' + \" = \" + str(\"{:.2f}\".format(df_base_statistic[metric]['mean'])), color='green')\n",
        "  ax.text(right + 0.3, LIC[metric], \"LIC = \" + str(\"{:.2f}\".format(LIC[metric])), color='red')"
      ],
      "metadata": {
        "id": "z_xJr_gQMUfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Verifica se os gráficos estão dentro ou fora de controle a partir do threshold estabelecido\n",
        "de 20% para a taxa de violação do gráfico. Esse threshold é escolhido devido aos cortes\n",
        "feitos no conjunto de dados para definição dos limites superiores e inferiores. No caso,\n",
        "os limites inferiores e superiores são definidos a partir do 5º e do 95º percentil do dataframe,\n",
        "portanto, o threshold tem que ser acima de 10% pelo menos, entre 15 a 20% é o ideal.\n",
        "Como estamos observando diversos endpoints, encontrar uma alteração significativa de desempenho\n",
        "pode ser um pouco díficil, porém, tem a questão do possível erro gerado a partir da escala das informações,\n",
        "portanto, estamos utilizando 20% podendo caber uma avaliação quanto\n",
        "a pontos de estatística descritiva dos dataframes, afim de invalidar dados imprecisos.\n",
        "Dados imprecisos são dados providos de escalas feitas sob uma relação que não representa linearidade,\n",
        "normalmente, são relações que possuem um baixo R².\n",
        "\"\"\"\n",
        "\n",
        "for index, metric in enumerate(analyzable_metrics):\n",
        "\n",
        "  # Verifica normalidade a partir do shapiro (Se pvalue < 0.05, conjunto de dados não normal)\n",
        "  _, pvalue_base = stats.shapiro(dfs_target[metric][metric])\n",
        "  _, pvalue_target_scaled = stats.shapiro(dfs_target_scaled[metric][metric])\n",
        "  if pvalue_base < 0.05 or pvalue_target_scaled < 0.05:\n",
        "    continue\n",
        "\n",
        "  sum_of_violation = 0\n",
        "  for metric_data in dfs_target[metric][metric]:\n",
        "    if metric_data > LSC[metric] or metric_data < LIC[metric]:\n",
        "      sum_of_violation += 1\n",
        "\n",
        "  print(f\"Métrica: {metric}\")\n",
        "  print(f\"Número de violações: {sum_of_violation}\")\n",
        "  print(f\"Número total de amostras: {dfs_target_scaled[metric][metric].count()}\")\n",
        "\n",
        "  violation_ratio = sum_of_violation / dfs_target_scaled[metric][metric].count()\n",
        "  threshold = 0.20 #\n",
        "\n",
        "  print(f\"Taxa de violação: {violation_ratio}\\nThreshold pré-definido: {threshold}\")\n",
        "  if violation_ratio > threshold:\n",
        "    print('Gráfico fora de controle')\n",
        "  else:\n",
        "    print('Gráfico dentro do controle')\n",
        "\n",
        "  # Pula linha entre resultados de métricas\n",
        "  if index < len(possible_metrics) - 1:\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "k4H_VRh5MUaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Resultado do teste de Shapiro Wilk para conjuntos de dados base e alvo já em escala e filtrado.\n",
        "\"\"\"\n",
        "for metric in analyzable_metrics:\n",
        "  print(metric)\n",
        "  print(f\"ANTES ----- Base: {stats.shapiro(df_target_scaled[metric])} ------- Target: {stats.shapiro(df_target[metric])}\")\n",
        "  print(f\"DEPOIS -----Base: {stats.shapiro(dfs_target_scaled[metric][metric])} ------- Target: {stats.shapiro(dfs_target[metric][metric])}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "5vc7_M6tpypi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Plote dos histogramas com a curva feita a partir estimativa de densidade por Kernel (KDE)\n",
        "Conjunto de dados base escalado.\n",
        "\"\"\"\n",
        "for metric in analyzable_metrics:\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
        "  fig.suptitle(\"Antes                                x                                Depois\")\n",
        "  sns.histplot(df_target_scaled[metric], kde=True, ax=ax1)\n",
        "  sns.histplot(dfs_target_scaled[metric][metric], kde=True, ax=ax2)\n",
        "  q1 = np.percentile(df_target_scaled[metric], 25)\n",
        "  q3 = np.percentile(df_target_scaled[metric], 75)\n",
        "  iqr = q3 - q1\n",
        "  ax1.axvline(q1 - (1.5*iqr), color='red', ls='--', label='LIC', ymin = 0, ymax = 0.95 )\n",
        "  ax1.axvline(q3 + (1.5*iqr), color='green', ls='--', label='LSC', ymin = 0, ymax = 0.95 )\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tKOiFk6_sVD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Plote dos histogramas com a curva feita a partir estimativa de densidade por Kernel (KDE)\n",
        "Conjunto de dados alvo.\n",
        "\"\"\"\n",
        "for metric in analyzable_metrics:\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
        "  fig.suptitle(\"Antes                                x                                Depois\")\n",
        "  sns.histplot(df_target[metric], kde=True, ax=ax1)\n",
        "  sns.histplot(dfs_target[metric][metric], kde=True, ax=ax2)\n",
        "  q1 = np.percentile(df_target[metric], 25)\n",
        "  q3 = np.percentile(df_target[metric], 75)\n",
        "  iqr = q3 - q1\n",
        "  ax1.axvline(q1 - (1.5*iqr), color='red', ls='--', label='LIC', ymin = 0, ymax = 0.95 )\n",
        "  ax1.axvline(q3 + (1.5*iqr), color='green', ls='--', label='LSC', ymin = 0, ymax = 0.95 )\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UECcZD-YRuQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Gráficos qq do conjunto de dados base escalado [target_scaled] (antes x depois).\n",
        "\"\"\"\n",
        "for metric in analyzable_metrics:\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
        "  fig.suptitle(\"Antes                                x                                Depois\")\n",
        "  sm.qqplot(df_target_scaled[metric], ax=ax1)\n",
        "  sm.qqplot(dfs_target_scaled[metric][metric], ax=ax2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kc5IVMsiKjHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Gráficos qq do conjunto de dados alvo (antes x depois).\n",
        "\"\"\"\n",
        "for metric in analyzable_metrics:\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
        "  fig.suptitle(\"Antes                                x                                Depois\")\n",
        "  sm.qqplot(df_target[metric], ax=ax1)\n",
        "  sm.qqplot(dfs_target[metric][metric], ax=ax2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3_aYMxMrKVHg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}